/home/sam/github/data-investor-pipeline
├── code_report.py
├── config
├── custom_tree_and_files_corrected.txt
├── .env
├── .env.example
├── .gitignore
├── intestion_data_fmp.ipynb
├── LICENSE
├── README.md
├── src
│   ├── data_ingestion
│   │   ├── db_connector.py
│   │   └── __init__.py
│   ├── run.py
│   └── utils
│       ├── utils_data.py
│       └── utils_logger.py
└── .vscode
    └── tasks.json

6 directories, 14 files


=== Content of /home/sam/github/data-investor-pipeline/.env.example ===

DB_TYPE=LOCAL  # Options: PLANETSCALE, LOCAL, MONGO

FMP_SECRET_KEY=

DB_HOST=
DB_USERNAME=
DB_PASSWORD=
DB_NAME=
  
DB_HOST_LOCAL=localhost
DB_USERNAME_LOCAL=
DB_PASSWORD_LOCAL=
DB_NAME_LOCAL=


MONGO_URI=
MONGO_DB_NAME=
```

=== Content of /home/sam/github/data-investor-pipeline/code_report.py ===

Code present but not reported for space reasons

=== Content of /home/sam/github/data-investor-pipeline/src/run.py ===

# run.py

# Import necessary libraries
from datetime import datetime
from dotenv import load_dotenv
import os
from loguru import logger
import sys

# Import custom modules
from data_ingestion.db_connector import DBConnector

from fetch_data.fetch_equities import (
    fetch_and_store_profiles,
    fetch_and_store_financial_statements,
    fetch_and_store_hist_prices,
    fetch_and_store_market_cap_data,
)
from data_storage.models_mongo import (
    create_profiles_collection,
    create_cashflows_collection,
)


def configure_logger():
    """
    Configure the Loguru logger settings.
    """
    logger.remove()
    logger.add(
        lambda msg: sys.stderr.write(msg),
        format="{time:YYYY-MM-DD HH:mm:ss} | {level} | {function}:{line} - {message}",
    )
    logger.add(
        "./logs/data_pipeline.log", rotation="1 day", level="INFO", serialize=True
    )


def main():
    load_dotenv()
    configure_logger()

    run_id = datetime.now().strftime("%Y/%m/%d_%H:%M:%S")
    FMP_API_KEY = os.getenv("FMP_SECRET_KEY")
    db_type = os.getenv("DB_TYPE", "LOCAL")

    # Initialize DB Connector based on the type
    print(f"Connecting to DB: {db_type}")
    db_connector = DBConnector()

    db_connector.initialize_db(db_type)

    common_args = {
        "db_connector": db_connector,
        "api_key": FMP_API_KEY,
        "run_id": run_id,
    }

    try:
        logger.bind(run_id=run_id).info("Starting data pipeline")
        db_uri = os.getenv("MONGO_URI")
        db_name = os.getenv("MONGO_DB_NAME")
        create_profiles_collection(db_uri, db_name)

        create_cashflows_collection(db_uri, db_name)

        fetch_and_store_profiles(**common_args)
        fetch_and_store_financial_statements(**common_args)
        # fetch_and_store_hist_prices(**common_args)
        # fetch_and_store_market_cap_data(**common_args)

    except Exception as e:
        logger.bind(run_id=run_id).exception("An error occurred: {}", e)


if __name__ == "__main__":
    main()


=== Content of /home/sam/github/data-investor-pipeline/src/utils/utils_logger.py ===

import sys


from loguru import logger


def configure_logger():
    """
    Configure the Loguru logger settings.
    """
    logger.remove()
    logger.add(
        lambda msg: sys.stderr.write(msg),
        format="{time:YYYY-MM-DD HH:mm:ss} | {level} | {function}:{line} - {message}",
    )
    logger.add(
        "./logs/data_pipeline.log", rotation="1 day", level="INFO", serialize=True
    )


=== Content of /home/sam/github/data-investor-pipeline/src/utils/utils_data.py ===

from urllib.request import urlopen

import certifi
import json


def get_jsonparsed_data(url):
    response = urlopen(url, cafile=certifi.where())
    data = response.read().decode("utf-8")
    return json.loads(data)


=== Content of /home/sam/github/data-investor-pipeline/src/data_ingestion/db_connector.py ===

import os
import polars as pl
from pymongo import MongoClient
from pymongo.server_api import ServerApi
from sqlalchemy import create_engine
from sqlalchemy.orm import sessionmaker
from loguru import logger


class DBConnector:
    def __init__(self):
        self.engine = None
        self.SessionLocal = None
        self.mongo_client = None
        self.mongo_db = None

    def connect_sqlalchemy(self, db_url, connect_args=None):
        if connect_args is None:
            connect_args = {}
        try:
            self.engine = create_engine(db_url, connect_args=connect_args)
            self.SessionLocal = sessionmaker(autoflush=False, bind=self.engine)
        except Exception as e:
            logger.error(f"SQLAlchemy connection error: {e}")

    def connect_mongodb(self, uri, db_name):
        try:
            self.mongo_client = MongoClient(uri, server_api=ServerApi("1"))
            self.mongo_db = self.mongo_client[db_name]
            self.mongo_client.admin.command("ping")
            logger.info("Successfully connected to MongoDB")
        except Exception as e:
            logger.error(f"MongoDB connection error: {e}")

    def initialize_db(self, connection_type):
        if connection_type == "PLANETSCALE":
            db_url = self.build_mysql_url()
            ssl_args = {"ssl": {"ca": "/etc/ssl/certs/ca-certificates.crt"}}
            self.connect_sqlalchemy(db_url, ssl_args)

        elif connection_type == "LOCAL":
            db_url = self.build_postgres_url()
            self.connect_sqlalchemy(db_url)

        elif connection_type == "MONGO":
            mongo_uri = os.getenv("MONGO_URI")
            mongo_db_name = os.getenv("MONGO_DB_NAME")
            self.connect_mongodb(mongo_uri, mongo_db_name)

        else:
            raise ValueError("Invalid connection type specified")

    @staticmethod
    def build_mysql_url():
        return f"mysql+pymysql://{os.getenv('DB_USERNAME')}:{os.getenv('DB_PASSWORD')}@{os.getenv('DB_HOST')}/{os.getenv('DB_NAME')}"

    @staticmethod
    def build_postgres_url():
        return f"postgresql://{os.getenv('DB_USERNAME_LOCAL')}:{os.getenv('DB_PASSWORD_LOCAL')}@{os.getenv('DB_HOST_LOCAL')}/{os.getenv('DB_NAME_LOCAL')}"

    def write_to_mongo(self, collection_name, df):
        try:
            records = df.to_dicts()
            collection = self.mongo_db[collection_name]
            result = collection.insert_many(records)
            logger.info(f"Inserted document IDs: {result.inserted_ids}")
        except Exception as e:
            logger.error(f"Failed to write to MongoDB. Error: {e}")

    def read_from_mongo(self, collection_name, query=None):
        if query is None:
            query = {}
        try:
            collection = self.mongo_db[collection_name]
            data = list(collection.find(query))
            return pl.DataFrame(data)
        except Exception as e:
            logger.error(f"Failed to read from MongoDB. Error: {e}")
            return pl.DataFrame()

    def create_collection(self, db_uri, db_name, collection_name, validator=None):
        if validator is None:
            validator = {}
        try:
            client = MongoClient(db_uri)
            db = client[db_name]
            db.create_collection(collection_name, validator=validator)
            db.command("collMod", collection_name, validator=validator)
        except Exception as e:
            logger.error(f"Error creating collection: {e}")


# # Initialize DBConnector
# db = DBConnector()
# db.initialize_db("MONGO")
# db.create_collection(
#     os.getenv("MONGO_URI"), os.getenv("MONGO_DB_NAME"), "your_collection_name"
# )
